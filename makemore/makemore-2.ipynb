{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f63ad2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import importlib\n",
    "mm = importlib.import_module(\"makemore-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3353a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da96d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = mm.load_words_from_file('names.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe4f71",
   "metadata": {},
   "source": [
    "# what are we trying to do\n",
    "\n",
    "add more context in training data. we don't want input-output pairs to just be $(c_k, c_{k+1})$, but rather $((c_{k-L+1}, \\ldots, c_k), c_{k+1})$ for context length $L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c898710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = mm.CHAR_INDICES['.']\n",
    "context_length = 3\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for word in words:\n",
    "  # initial context_array = [0, 0, 0]\n",
    "  context_array = [start_idx] * context_length\n",
    "  xs.append(context_array.copy())\n",
    "  word = f'{word}.'\n",
    "\n",
    "  # loop invariant:\n",
    "  #   - xs has a sequence of inputs already processed (possibly empty),\n",
    "  #     followed by the next input to be processed\n",
    "  #   - xs = [x_1, ..., x_{k-1}, x_k]^T\n",
    "  #   - ys = [y_1, ..., y_{k-1}]^T has a sequence of outputs, one for each\n",
    "  #     of the inputs already processed.\n",
    "  for ch in word:\n",
    "    ch_idx = mm.CHAR_INDICES[ch]\n",
    "    ys.append(ch_idx)\n",
    "    # assuming training data contains no \".\"'s and has properly been filtered out,\n",
    "    # then the only way ch_idx == 0 is if we're at the end\n",
    "    if ch_idx != 0:\n",
    "      context_array.pop(0)\n",
    "      context_array.append(ch_idx)\n",
    "      xs.append(context_array.copy())\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa65787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0, 26],\n",
       "        [ 0, 26, 25],\n",
       "        [26, 25,  5],\n",
       "        [25,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 26],\n",
       "        [ 0, 26, 25],\n",
       "        [26, 25,  8],\n",
       "        [25,  8,  5],\n",
       "        [ 8,  5,  5],\n",
       "        [ 5,  5, 13],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 26],\n",
       "        [ 0, 26, 25],\n",
       "        [26, 25, 11],\n",
       "        [25, 11,  5],\n",
       "        [11,  5,  5],\n",
       "        [ 5,  5, 13],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 26],\n",
       "        [ 0, 26, 25],\n",
       "        [26, 25, 12],\n",
       "        [25, 12,  1],\n",
       "        [12,  1, 19],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 26],\n",
       "        [ 0, 26, 25],\n",
       "        [26, 25, 18],\n",
       "        [25, 18,  1],\n",
       "        [18,  1, 14],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 26],\n",
       "        [ 0, 26, 25],\n",
       "        [26, 25, 18],\n",
       "        [25, 18,  9],\n",
       "        [18,  9,  5],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 26],\n",
       "        [ 0, 26, 25],\n",
       "        [26, 25, 18],\n",
       "        [25, 18, 15],\n",
       "        [18, 15, 14],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 26],\n",
       "        [ 0, 26, 26],\n",
       "        [26, 26, 25],\n",
       "        [26, 25, 26],\n",
       "        [25, 26, 24]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(xs)\n",
    "Y = torch.tensor(ys)\n",
    "# number of samples\n",
    "M = X.shape[0]\n",
    "X[M-50+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8ba502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 3]) torch.int64 torch.Size([228146]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X.dtype, Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b2ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[len(Y)- 50 + 1:len(Y)]\n",
    "#Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641253a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c8c05",
   "metadata": {},
   "source": [
    "# Using a character embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9526ed55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4241,  0.5769],\n",
       "        [-0.6277,  0.0143],\n",
       "        [-0.9878,  0.2228],\n",
       "        [-1.4256,  0.7473],\n",
       "        [-0.5949, -0.1887],\n",
       "        [-0.1495, -0.4329],\n",
       "        [-0.4959,  0.4085],\n",
       "        [ 0.2081, -0.9456],\n",
       "        [ 0.8445,  0.3077],\n",
       "        [ 0.0774, -0.2167],\n",
       "        [ 0.0821, -0.3223],\n",
       "        [-1.1067, -0.9847],\n",
       "        [ 0.2355,  1.7855],\n",
       "        [-2.0072,  0.5952],\n",
       "        [-0.6068,  0.0860],\n",
       "        [ 0.0625,  0.1150],\n",
       "        [-1.1692,  1.2160],\n",
       "        [-0.5986,  1.8403],\n",
       "        [-0.9995,  1.4243],\n",
       "        [-0.0282, -0.8051],\n",
       "        [-1.7092,  0.3798],\n",
       "        [ 1.0339, -0.4120],\n",
       "        [ 1.4762, -1.8294],\n",
       "        [-0.0424,  1.0475],\n",
       "        [-0.3213,  1.2027],\n",
       "        [-0.3261, -0.3309],\n",
       "        [-0.7989, -1.4962]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to embed each character as a d-dimensional char vector\n",
    "C = torch.randn((27, 2))\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8606f",
   "metadata": {},
   "source": [
    "X_proc = F.one_hot(X, num_classes=27)\n",
    "print(X_proc.shape)\n",
    "X_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2367ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = F.one_hot(X[8,:], num_classes=27)\n",
    "print(X[8,:])\n",
    "print(x_test.shape)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proc = F.one_hot(X, num_classes=27)\n",
    "print(X_proc.shape)\n",
    "X_proc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e6c329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 3, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d0bb83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7712,  0.1459, -2.5276, -0.4439],\n",
       "         [ 0.1954,  0.9009,  0.0099,  1.2254],\n",
       "         [ 0.1733,  1.3780,  0.1114,  0.5206],\n",
       "         [ 1.5242,  1.9523,  2.2758, -0.1949],\n",
       "         [-1.0266, -0.1732, -0.5256,  0.1714]],\n",
       "\n",
       "        [[ 1.0067,  1.0809,  0.2571,  0.4201],\n",
       "         [ 0.1419,  1.3223,  1.1053, -0.5849],\n",
       "         [-1.1458,  0.5297, -1.2569, -0.1491],\n",
       "         [-1.4250, -1.1838,  0.6424, -1.1906],\n",
       "         [-1.2454, -1.2507, -0.6623, -0.7152]],\n",
       "\n",
       "        [[-0.4293,  0.7219,  1.6887, -0.6467],\n",
       "         [ 0.9161, -1.2045,  0.8350,  1.8599],\n",
       "         [-1.4955, -0.1086, -0.9488,  0.5964],\n",
       "         [ 1.9429, -0.1013,  1.1199,  0.3472],\n",
       "         [ 0.0312,  0.3962, -0.4596,  0.8121]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn((3,5,4))\n",
    "print(A.shape)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cccaa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7712,  0.1459, -2.5276, -0.4439],\n",
       "         [ 0.1954,  0.9009,  0.0099,  1.2254],\n",
       "         [ 0.1733,  1.3780,  0.1114,  0.5206],\n",
       "         [ 1.5242,  1.9523,  2.2758, -0.1949],\n",
       "         [-1.0266, -0.1732, -0.5256,  0.1714]]),\n",
       " tensor([[ 1.0067,  1.0809,  0.2571,  0.4201],\n",
       "         [ 0.1419,  1.3223,  1.1053, -0.5849],\n",
       "         [-1.1458,  0.5297, -1.2569, -0.1491],\n",
       "         [-1.4250, -1.1838,  0.6424, -1.1906],\n",
       "         [-1.2454, -1.2507, -0.6623, -0.7152]]),\n",
       " tensor([[-0.4293,  0.7219,  1.6887, -0.6467],\n",
       "         [ 0.9161, -1.2045,  0.8350,  1.8599],\n",
       "         [-1.4955, -0.1086, -0.9488,  0.5964],\n",
       "         [ 1.9429, -0.1013,  1.1199,  0.3472],\n",
       "         [ 0.0312,  0.3962, -0.4596,  0.8121]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U1 = torch.unbind(A, dim=0)\n",
    "U1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49956ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9490, 0.6837, 0.3125]),\n",
       " tensor([-0.6820,  0.5063, -0.0372]),\n",
       " tensor([-1.5017, -0.0613, -0.2872]),\n",
       " tensor([-0.2989, -0.3521,  0.2945]),\n",
       " tensor([ 0.6310, -0.1917, -0.0373]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U2 = torch.unbind(A, dim=1)\n",
    "U2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b0998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
